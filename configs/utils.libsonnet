{
bert_trainable:true,
optimizer:"bert_adam",
lr:1e-5,
warmup:10000,
iden : {type:"identity"},
gcn:{type:"gcn",
        hdim:768,
        nlayers:2},
lstm:{type:"seq2seq",
    "seq2seq_encoder":{
     "type":"lstm",
     "input_size":768,
     "hidden_size":384,
     "batch_first":true,
     "bidirectional":true
     }},
SelfAttnSpan:{
    type:'self_attentive',
    input_dim:768
},
stacked_self_attention:{
     type:"seq2seq",
     seq2seq_encoder:{
     type:"stacked_self_attention",
        input_dim:768,
        hidden_dim:768,
        projection_dim:768,
        feedforward_hidden_dim:768,
        num_layers:2,
        num_attention_heads:4
     }
},
easy_graph_encoder:{
    type:'easy_graph_encoder',
    input_dim:768,
    num_layers:1,
    hidden_dims:768
},
multi_head_self_attention:{
    type:"seq2seq",
    "seq2seq_encoder":{
    type:"multi_head_self_attention",
    num_heads:4,
    input_dim:768,
    attention_dim:128,
    values_dim:128,
    output_projection_dim:768
}},

}
